Loading gmp version 6.2.1
Loading mpfr version 3.1.6
Loading mpc version 1.1.0
Loading zlib-ng version 2.1.6
Loading gcc version 9.4.0
2025-03-30 00:16:20.713952: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1743293781.309157 2155917 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1743293781.498223 2155917 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1743293783.000754 2155917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1743293783.000805 2155917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1743293783.000809 2155917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1743293783.000812 2155917 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-03-30 00:16:23.132775: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:  33%|███▎      | 1/3 [04:19<08:38, 259.28s/it]Downloading shards:  67%|██████▋   | 2/3 [08:39<04:20, 260.01s/it]Downloading shards: 100%|██████████| 3/3 [11:17<00:00, 213.26s/it]Downloading shards: 100%|██████████| 3/3 [11:17<00:00, 225.81s/it]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [01:24<02:49, 84.52s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [02:49<01:24, 84.65s/it]Loading checkpoint shards: 100%|██████████| 3/3 [03:42<00:00, 70.19s/it]Loading checkpoint shards: 100%|██████████| 3/3 [03:42<00:00, 74.08s/it]
Map:   0%|          | 0/76673 [00:00<?, ? examples/s]Map:   1%|▏         | 1000/76673 [00:00<00:34, 2200.38 examples/s]Map:   3%|▎         | 2000/76673 [00:00<00:30, 2477.34 examples/s]Map:   4%|▍         | 3000/76673 [00:01<00:28, 2620.47 examples/s]Map:   5%|▌         | 4000/76673 [00:01<00:27, 2673.19 examples/s]Map:   7%|▋         | 5000/76673 [00:01<00:29, 2471.22 examples/s]Map:   8%|▊         | 6000/76673 [00:02<00:27, 2576.29 examples/s]Map:   9%|▉         | 7000/76673 [00:02<00:28, 2420.52 examples/s]Map:  10%|█         | 8000/76673 [00:03<00:27, 2466.81 examples/s]Map:  12%|█▏        | 9000/76673 [00:03<00:26, 2547.59 examples/s]Map:  13%|█▎        | 10000/76673 [00:03<00:26, 2541.67 examples/s]Map:  14%|█▍        | 11000/76673 [00:04<00:24, 2641.81 examples/s]Map:  16%|█▌        | 12000/76673 [00:04<00:30, 2142.97 examples/s]Map:  17%|█▋        | 13000/76673 [00:05<00:29, 2189.96 examples/s]Map:  18%|█▊        | 14000/76673 [00:05<00:26, 2343.04 examples/s]Map:  20%|█▉        | 15000/76673 [00:06<00:25, 2460.57 examples/s]Map:  21%|██        | 16000/76673 [00:06<00:27, 2210.34 examples/s]Map:  22%|██▏       | 17000/76673 [00:07<00:25, 2308.36 examples/s]Map:  23%|██▎       | 18000/76673 [00:07<00:25, 2305.19 examples/s]Map:  25%|██▍       | 19000/76673 [00:08<00:28, 2014.16 examples/s]Map:  26%|██▌       | 20000/76673 [00:08<00:25, 2206.08 examples/s]Map:  27%|██▋       | 21000/76673 [00:08<00:23, 2335.20 examples/s]Map:  29%|██▊       | 22000/76673 [00:09<00:23, 2340.58 examples/s]Map:  30%|██▉       | 23000/76673 [00:09<00:23, 2329.47 examples/s]Map:  31%|███▏      | 24000/76673 [00:10<00:21, 2438.00 examples/s]Map:  33%|███▎      | 25000/76673 [00:10<00:20, 2531.70 examples/s]Map:  34%|███▍      | 26000/76673 [00:10<00:20, 2458.58 examples/s]Map:  35%|███▌      | 27000/76673 [00:11<00:19, 2499.00 examples/s]Map:  37%|███▋      | 28000/76673 [00:11<00:18, 2575.08 examples/s]Map:  38%|███▊      | 29000/76673 [00:12<00:18, 2585.21 examples/s]Map:  39%|███▉      | 30000/76673 [00:12<00:17, 2623.35 examples/s]Map:  40%|████      | 31000/76673 [00:12<00:17, 2666.44 examples/s]Map:  42%|████▏     | 32000/76673 [00:13<00:17, 2548.93 examples/s]Map:  43%|████▎     | 33000/76673 [00:13<00:17, 2541.29 examples/s]Map:  44%|████▍     | 34000/76673 [00:14<00:17, 2454.15 examples/s]Map:  46%|████▌     | 35000/76673 [00:14<00:16, 2483.36 examples/s]Map:  47%|████▋     | 36000/76673 [00:14<00:15, 2575.33 examples/s]Map:  48%|████▊     | 37000/76673 [00:15<00:15, 2513.36 examples/s]Map:  50%|████▉     | 38000/76673 [00:15<00:16, 2377.85 examples/s]Map:  51%|█████     | 39000/76673 [00:16<00:15, 2481.41 examples/s]Map:  52%|█████▏    | 40000/76673 [00:16<00:17, 2075.26 examples/s]Map:  53%|█████▎    | 41000/76673 [00:17<00:15, 2259.86 examples/s]Map:  55%|█████▍    | 42000/76673 [00:17<00:14, 2391.45 examples/s]Map:  56%|█████▌    | 43000/76673 [00:17<00:13, 2483.68 examples/s]Map:  57%|█████▋    | 44000/76673 [00:18<00:12, 2577.22 examples/s]Map:  59%|█████▊    | 45000/76673 [00:18<00:12, 2633.18 examples/s]Map:  60%|█████▉    | 46000/76673 [00:18<00:11, 2702.67 examples/s]Map:  61%|██████▏   | 47000/76673 [00:19<00:10, 2747.61 examples/s]Map:  63%|██████▎   | 48000/76673 [00:19<00:10, 2757.74 examples/s]Map:  64%|██████▍   | 49000/76673 [00:19<00:10, 2618.22 examples/s]Map:  65%|██████▌   | 50000/76673 [00:20<00:11, 2408.47 examples/s]Map:  67%|██████▋   | 51000/76673 [00:20<00:10, 2428.81 examples/s]Map:  68%|██████▊   | 52000/76673 [00:21<00:10, 2363.74 examples/s]Map:  69%|██████▉   | 53000/76673 [00:21<00:09, 2476.48 examples/s]Map:  70%|███████   | 54000/76673 [00:22<00:08, 2560.38 examples/s]Map:  72%|███████▏  | 55000/76673 [00:22<00:08, 2467.29 examples/s]Map:  73%|███████▎  | 56000/76673 [00:22<00:08, 2574.54 examples/s]Map:  74%|███████▍  | 57000/76673 [00:23<00:08, 2354.08 examples/s]Map:  76%|███████▌  | 58000/76673 [00:23<00:07, 2445.46 examples/s]Map:  77%|███████▋  | 59000/76673 [00:24<00:06, 2554.62 examples/s]Map:  78%|███████▊  | 60000/76673 [00:24<00:06, 2626.96 examples/s]Map:  80%|███████▉  | 61000/76673 [00:25<00:08, 1883.88 examples/s]Map:  81%|████████  | 62000/76673 [00:25<00:07, 1985.59 examples/s]Map:  82%|████████▏ | 63000/76673 [00:26<00:06, 2154.94 examples/s]Map:  83%|████████▎ | 64000/76673 [00:26<00:05, 2112.66 examples/s]Map:  85%|████████▍ | 65000/76673 [00:27<00:05, 2166.19 examples/s]Map:  86%|████████▌ | 66000/76673 [00:27<00:04, 2238.72 examples/s]Map:  87%|████████▋ | 67000/76673 [00:27<00:04, 2385.23 examples/s]Map:  89%|████████▊ | 68000/76673 [00:28<00:03, 2378.53 examples/s]Map:  90%|████████▉ | 69000/76673 [00:28<00:03, 2387.55 examples/s]Map:  91%|█████████▏| 70000/76673 [00:28<00:02, 2501.32 examples/s]Map:  93%|█████████▎| 71000/76673 [00:29<00:02, 2581.70 examples/s]Map:  94%|█████████▍| 72000/76673 [00:29<00:02, 2272.37 examples/s]Map:  95%|█████████▌| 73000/76673 [00:30<00:01, 2372.90 examples/s]Map:  97%|█████████▋| 74000/76673 [00:30<00:01, 2353.45 examples/s]Map:  98%|█████████▊| 75000/76673 [00:31<00:00, 2434.20 examples/s]Map:  99%|█████████▉| 76000/76673 [00:31<00:00, 2539.79 examples/s]Map: 100%|██████████| 76673/76673 [00:31<00:00, 2548.48 examples/s]Map: 100%|██████████| 76673/76673 [00:36<00:00, 2118.36 examples/s]
Map:   0%|          | 0/12030 [00:00<?, ? examples/s]Map:   8%|▊         | 1000/12030 [00:00<00:05, 2190.75 examples/s]Map:  17%|█▋        | 2000/12030 [00:00<00:04, 2431.43 examples/s]Map:  25%|██▍       | 3000/12030 [00:01<00:03, 2363.55 examples/s]Map:  33%|███▎      | 4000/12030 [00:01<00:03, 2509.33 examples/s]Map:  42%|████▏     | 5000/12030 [00:02<00:02, 2476.47 examples/s]Map:  50%|████▉     | 6000/12030 [00:02<00:02, 2042.22 examples/s]Map:  58%|█████▊    | 7000/12030 [00:03<00:02, 2235.34 examples/s]Map:  67%|██████▋   | 8000/12030 [00:03<00:01, 2396.20 examples/s]Map:  75%|███████▍  | 9000/12030 [00:03<00:01, 2483.82 examples/s]Map:  83%|████████▎ | 10000/12030 [00:04<00:00, 2463.86 examples/s]Map:  91%|█████████▏| 11000/12030 [00:04<00:00, 2456.33 examples/s]Map: 100%|█████████▉| 12000/12030 [00:05<00:00, 2378.52 examples/s]Map: 100%|██████████| 12030/12030 [00:05<00:00, 2035.74 examples/s]
Map:   0%|          | 0/10943 [00:00<?, ? examples/s]Map:   9%|▉         | 1000/10943 [00:00<00:04, 2216.63 examples/s]Map:  18%|█▊        | 2000/10943 [00:00<00:03, 2257.24 examples/s]Map:  27%|██▋       | 3000/10943 [00:01<00:03, 2254.18 examples/s]Map:  37%|███▋      | 4000/10943 [00:01<00:02, 2425.76 examples/s]Map:  46%|████▌     | 5000/10943 [00:02<00:02, 2553.09 examples/s]Map:  55%|█████▍    | 6000/10943 [00:02<00:01, 2622.11 examples/s]Map:  64%|██████▍   | 7000/10943 [00:02<00:01, 2670.17 examples/s]Map:  73%|███████▎  | 8000/10943 [00:03<00:01, 2367.08 examples/s]Map:  82%|████████▏ | 9000/10943 [00:03<00:00, 2335.53 examples/s]Map:  91%|█████████▏| 10000/10943 [00:04<00:00, 2401.68 examples/s]Map: 100%|██████████| 10943/10943 [00:04<00:00, 2510.18 examples/s]Map: 100%|██████████| 10943/10943 [00:05<00:00, 2101.14 examples/s]
/work/pi_jaimedavila_umass_edu/asharda_umass_edu/test_LLM/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/work/pi_jaimedavila_umass_edu/asharda_umass_edu/LLM_scripts/llama2_7b/train_bot.py:98: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/28752 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
/work/pi_jaimedavila_umass_edu/asharda_umass_edu/test_LLM/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
  0%|          | 1/28752 [02:13<1067:11:30, 133.63s/it]  0%|          | 2/28752 [04:26<1063:29:34, 133.17s/it]  0%|          | 3/28752 [06:38<1060:37:34, 132.81s/it]  0%|          | 4/28752 [08:51<1059:14:22, 132.64s/it]  0%|          | 5/28752 [11:03<1059:04:31, 132.63s/it]  0%|          | 6/28752 [13:16<1058:38:51, 132.58s/it]  0%|          | 7/28752 [15:28<1058:04:23, 132.51s/it]  0%|          | 8/28752 [17:41<1059:02:31, 132.64s/it]  0%|          | 9/28752 [19:54<1059:03:18, 132.64s/it]  0%|          | 10/28752 [22:06<1058:52:31, 132.63s/it]                                                          0%|          | 10/28752 [22:06<1058:52:31, 132.63s/it]  0%|          | 11/28752 [24:19<1059:10:21, 132.67s/it]  0%|          | 12/28752 [26:32<1059:13:54, 132.68s/it]  0%|          | 13/28752 [28:45<1059:17:16, 132.69s/it]  0%|          | 14/28752 [30:57<1058:58:44, 132.66s/it]  0%|          | 15/28752 [33:10<1059:07:33, 132.68s/it]  0%|          | 16/28752 [35:22<1058:56:54, 132.66s/it]  0%|          | 17/28752 [37:35<1058:44:43, 132.64s/it]  0%|          | 18/28752 [39:48<1058:30:18, 132.62s/it]  0%|          | 19/28752 [42:00<1058:14:36, 132.59s/it]slurmstepd-gypsum-gpu073: error: *** JOB 30777712 ON gypsum-gpu073 CANCELLED AT 2025-03-30T01:16:07 DUE TO TIME LIMIT ***
